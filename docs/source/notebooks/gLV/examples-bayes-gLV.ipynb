{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f07fa1f2-187e-4ce0-af95-31d6120977fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T13:56:16.564066Z",
     "start_time": "2024-09-05T13:56:15.201621Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from mimic.utilities import *\n",
    "\n",
    "from mimic.model_infer.infer_gLV_bayes import *\n",
    "from mimic.model_infer import *\n",
    "from mimic.model_simulate import *\n",
    "from mimic.model_simulate.sim_gLV import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import arviz as az\n",
    "import pymc as pm\n",
    "import pytensor.tensor as at\n",
    "import pickle\n",
    "import cloudpickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82eb9f01",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Used Bayesian inference to infer the parameters of a (linearised) gLV model\n",
    "\n",
    "The generalized Lotka-Volterra equation takes the form\n",
    "\n",
    "$$ \\frac{dX_i}{dt} = \\mu_i X_i + X_i M_{ij} X_j + X_i \\epsilon_{il} u_l $$\n",
    "\n",
    "where:\n",
    "-   $X_i$ is the concentration of a species\n",
    "-   $\\mu_i$ is its specific growth rate\n",
    "-   $M_{ij}$ is the effect of the interaction of species $i$ on species $j$\n",
    "-   $\\epsilon_{il}$ is the susceptibility to the time-dependent perturbation $u_l$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4324950",
   "metadata": {},
   "source": [
    "### Bayesian inference with no shrinkage    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7e4c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in pickled simulated parameters, mu, M, epsilon\n",
    "num_species = 5\n",
    "with open(\"params-s5.pkl\", \"rb\") as f:\n",
    "    params = pickle.load(f)\n",
    "M = params[\"M\"]\n",
    "mu = params[\"mu\"]\n",
    "epsilon = params[\"epsilon\"]\n",
    "\n",
    "# read in the data\n",
    "num_timecourses = 1\n",
    "data = pd.read_csv(\"data-s5-r1.csv\")\n",
    "times = data.iloc[:, 0].values\n",
    "\n",
    "yobs = data.iloc[:, 1:6].values\n",
    "\n",
    "X, F = linearize_time_course_16S(yobs, times)\n",
    "\n",
    "# Set priors\n",
    "mu_prior = [1.0, 1.0, 1.0, 1.0, 1.0] \n",
    "M_prior = 0.0\n",
    "\n",
    "# Do inference\n",
    "inference = infergLVbayes(X, F, mu_prior, M_prior)\n",
    "idata = inference.run_bayes_gLV()\n",
    "\n",
    "summary = az.summary(idata, var_names=[\"mu_hat\", \"M_ii_hat\", \"M_ij_hat\", \"M_hat\", \"sigma\"])\n",
    "print(summary[[\"mean\", \"sd\", \"r_hat\"]])\n",
    "\n",
    "# Save posterior samples to file\n",
    "az.to_netcdf(idata, 'model_posterior.nc')\n",
    "\n",
    "# get median mu_hat and M_hat \n",
    "mu_h = np.median(idata.posterior[\"mu_hat\"].values, axis=(0,1) ).reshape(-1)\n",
    "M_h = np.median(idata.posterior[\"M_hat\"].values, axis=(0,1) )\n",
    "\n",
    "# compare fitted with simulated parameters\n",
    "compare_params(mu=(mu, mu_h), M=(M, M_h))\n",
    "\n",
    "predictor = sim_gLV(num_species=num_species, M=M_h, mu=mu_h)\n",
    "yobs_h, _, _, _, _ = predictor.simulate(times=times, init_species=yobs[0])\n",
    "plot_fit_gLV(yobs, yobs_h, times)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13d05a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in pickled simulated parameters, mu, M, epsilon\n",
    "num_species = 5\n",
    "with open(\"params-s5.pkl\", \"rb\") as f:\n",
    "    params = pickle.load(f)\n",
    "M = params[\"M\"]\n",
    "mu = params[\"mu\"]\n",
    "epsilon = params[\"epsilon\"]\n",
    "\n",
    "# read in the data\n",
    "num_timecourses = 3\n",
    "data = pd.read_csv(\"data-s5-r3.csv\")\n",
    "times = data.iloc[:, 0].values\n",
    "\n",
    "yobs_1 = data.iloc[:, 1:(num_species+1)].values\n",
    "yobs_2 = data.iloc[:, (num_species+1):(2*num_species+1)].values\n",
    "yobs_3 = data.iloc[:, (2*num_species+1):(3*num_species+1)].values\n",
    "ryobs = np.array([yobs_1, yobs_2, yobs_3])\n",
    "\n",
    "X = np.array([], dtype=np.double).reshape(0, num_species+1)\n",
    "F = np.array([], dtype=np.double).reshape(0, num_species)\n",
    "\n",
    "for timecourse_idx in range(num_timecourses):\n",
    "    Xs, Fs = linearize_time_course_16S(ryobs[timecourse_idx], times)\n",
    "    X = np.vstack([X, Xs])\n",
    "    F = np.vstack([F, Fs])\n",
    "\n",
    "# Set priors\n",
    "mu_prior = [1.28, 0.56, 2.07, 1.0, 1.0] \n",
    "M_prior = 0.0\n",
    "\n",
    "# Do inference\n",
    "inference = infergLVbayes(X, F, mu_prior, M_prior)\n",
    "idata = inference.run_bayes_gLV()\n",
    "\n",
    "summary = az.summary(idata, var_names=[\"mu_hat\", \"M_ii_hat\", \"M_ij_hat\", \"M_hat\", \"sigma\"])\n",
    "#print(summary[[\"mean\", \"sd\", \"r_hat\"]])\n",
    "\n",
    "# Save posterior samples to file\n",
    "az.to_netcdf(idata, 'model_posterior.nc')\n",
    "\n",
    "# get median mu_hat and M_hat\n",
    "mu_h = np.median(idata.posterior[\"mu_hat\"].values, axis=(0,1) ).reshape(-1)\n",
    "M_h = np.median(idata.posterior[\"M_hat\"].values, axis=(0,1) )\n",
    "\n",
    "compare_params(mu=(mu, mu_h), M=(M, M_h))\n",
    "\n",
    "predictor = sim_gLV(num_species=num_species, M=M_h, mu=mu_h)\n",
    "\n",
    "# plot comparison of simulated and predicted timeseries\n",
    "for timecourse_idx in range(num_timecourses):\n",
    "    yobs_h, _, _, _, _ = predictor.simulate(times=times, init_species=ryobs[timecourse_idx,0,:])\n",
    "    plot_fit_gLV(ryobs[timecourse_idx], yobs_h, times)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304e08bd",
   "metadata": {},
   "source": [
    "### Bayesian inference with shrinkage: Horseshoe prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a759a1de8b48255",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T16:39:59.958342Z",
     "start_time": "2024-09-04T16:39:59.776400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read in pickled simulated parameters, mu, M, epsilon\n",
    "num_species = 5\n",
    "with open(\"params-s5.pkl\", \"rb\") as f:\n",
    "    params = pickle.load(f)\n",
    "M = params[\"M\"]\n",
    "mu = params[\"mu\"]\n",
    "epsilon = params[\"epsilon\"]\n",
    "\n",
    "# read in the data\n",
    "num_timecourses = 1\n",
    "data = pd.read_csv(\"data-s5-r1.csv\")\n",
    "times = data.iloc[:, 0].values\n",
    "\n",
    "nX = num_species\n",
    "n_obs = times.shape[0] - 1\n",
    "noise_stddev = 0.1\n",
    "\n",
    "# Params for shrinkage on M_ij (non diagonal elements)\n",
    "DA = nX*nX - nX\n",
    "DA0 = 3     # expected number of non zero entries in M_ij\n",
    "N = n_obs - 2\n",
    "\n",
    "inference = infergLVbayes(X, F, mu_prior, M_prior, DA=DA, DA0=DA0, N=N, noise_stddev=noise_stddev)\n",
    "idata = inference.run_bayes_gLV_shrinkage()\n",
    "\n",
    "# print summary\n",
    "summary = az.summary(idata, var_names=[\"mu_hat\", \"M_ii_hat\", \"M_ij_hat\", \"M_hat\", \"sigma\"])\n",
    "print(summary[[\"mean\", \"sd\", \"r_hat\"]])\n",
    "\n",
    "# Write posterior samples to file\n",
    "az.to_netcdf(idata, 'model_posterior.nc')\n",
    "\n",
    "# get median mu_hat and M_hat \n",
    "mu_h = np.median(idata.posterior[\"mu_hat\"].values, axis=(0,1) ).reshape(-1)\n",
    "M_h = np.median(idata.posterior[\"M_hat\"].values, axis=(0,1) )\n",
    "\n",
    "# compare fitted with simulated parameters\n",
    "compare_params(mu=(mu, mu_h), M=(M, M_h))\n",
    "\n",
    "predictor = sim_gLV(num_species=num_species, M=M_h, mu=mu_h)\n",
    "yobs_h, _, _, _, _ = predictor.simulate(times=times, init_species=yobs[0])\n",
    "plot_fit_gLV(yobs, yobs_h, times)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77b7d49",
   "metadata": {},
   "source": [
    "### Bayesian inference with shrinkage and a perturbation with unknown interactions\n",
    "Now we will do inference with the Horseshoe prior for shrinkage but now we include a perturbation (assuming unknown interaction terms). This gives more identifiability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d6c2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_timecourses = 3\n",
    "num_perturbations = 1\n",
    "data = pd.read_csv(\"data-s5-r3-p1.csv\")\n",
    "times = data.iloc[:, 0].values\n",
    "\n",
    "yobs_1 = data.iloc[:, 1:(num_species+1)].values\n",
    "yobs_2 = data.iloc[:, (num_species+1):(2*num_species+1)].values\n",
    "yobs_3 = data.iloc[:, (2*num_species+1):(3*num_species+1)].values\n",
    "ryobs = np.array([yobs_1, yobs_2, yobs_3])\n",
    "\n",
    "# create the perturbation signal\n",
    "def pert_fn(t):\n",
    "    if 2.0 <= t < 2.2 or 3.0 <= t < 3.2 or 4.0 <= t < 4.2:\n",
    "        return np.array([1])\n",
    "    else: \n",
    "        return np.array([0])\n",
    "\n",
    "u = np.array([pert_fn(t)[0] for t in times])\n",
    "u = u.astype(int)\n",
    "\n",
    "X = np.array([], dtype=np.double).reshape(0, num_species+2)\n",
    "F = np.array([], dtype=np.double).reshape(0, num_species)\n",
    "\n",
    "for timecourse_idx in range(num_timecourses):\n",
    "    Xs, Fs = linearize_time_course_16S_u(ryobs[timecourse_idx], times, u)\n",
    "    X = np.vstack([X, Xs])\n",
    "    F = np.vstack([F, Fs])\n",
    "\n",
    "nX = num_species\n",
    "n_obs = times.shape[0] - 1\n",
    "noise_stddev = 0.1\n",
    "\n",
    "# Params for shrinkage on M_ij (non diagonal elements)\n",
    "DA = nX*nX - nX\n",
    "DA0 = 3     # expected number of non zero entries in M_ij\n",
    "N = n_obs - 2\n",
    "\n",
    "inference = infergLVbayes(X, F, mu_prior, M_prior, DA=DA, DA0=DA0, N=N, noise_stddev=noise_stddev, epsilon=epsilon)\n",
    "idata = inference.run_bayes_gLV_shrinkage_pert()\n",
    "\n",
    "# print summary\n",
    "summary = az.summary(idata, var_names=[\"mu_hat\", \"M_ii_hat\", \"M_ij_hat\", \"M_hat\", \"epsilon_hat\", \"sigma\"])\n",
    "print(summary[[\"mean\", \"sd\", \"r_hat\"]])\n",
    "\n",
    "# Write posterior samples to file\n",
    "az.to_netcdf(idata, 'model_posterior.nc')\n",
    "\n",
    "num_species = 5\n",
    "with open(\"params-s5.pkl\", \"rb\") as f:\n",
    "    params = pickle.load(f)\n",
    "M = params[\"M\"]\n",
    "mu = params[\"mu\"]\n",
    "epsilon = params[\"epsilon\"]\n",
    "\n",
    "\n",
    "# get median mu_hat and M_hat\n",
    "mu_h = np.median(idata.posterior[\"mu_hat\"].values, axis=(0,1) ).reshape(-1)\n",
    "M_h = np.median(idata.posterior[\"M_hat\"].values, axis=(0,1) )\n",
    "e_h = np.median(idata.posterior[\"epsilon_hat\"].values, axis=(0,1) ).T\n",
    "\n",
    "print(e_h.shape)\n",
    "\n",
    "predictor = sim_gLV(num_species=num_species,\n",
    "                    num_perturbations=1,\n",
    "                    M=M_h,\n",
    "                    mu=mu_h,\n",
    "                    epsilon=e_h,\n",
    "                    )\n",
    "\n",
    "# # plot comparison of simulated and predicted timeseries\n",
    "for timecourse_idx in range(num_timecourses):\n",
    "    yobs_h, _, _, _, _ = predictor.simulate(times=times, init_species=ryobs[timecourse_idx,0,:], u=pert_fn)\n",
    "    plot_fit_gLV(ryobs[timecourse_idx], yobs_h, times)\n",
    "\n",
    "compare_params(mu=(mu, mu_h), M=(M, M_h), e=(epsilon, e_h))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
